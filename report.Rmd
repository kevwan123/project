---
title: "report.Rmd"
output: pdf_document
date: "2022-11-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::include_graphics("outputs/variancebycomponents.tiff")

library(tidyverse)
#library(reticulate)
library(tidyr)
#library(matlab)
library(MASS)
library(stats)
# library(nlme)
library(tibble)
library(dplyr)
library(data.table)
# library(assist)
library(mgcv)
library(ggplot2)
# library(lme4)
#library(kernlab)
#library(plotly)
# library(numDeriv)
# library(randtoolbox)
# library(mrgsolve)
# library(parallel)
# library(BSDA)
# library(epitools)
#library(rdist)
#library(gbm)
library(glmnet)
getwd()
data = read.csv("brain_stroke.csv")
attach(data)
```


# Abstract

The goal of this document is to study how certain covariates in the Brain Stroke Dataset depend on eachother. The covariates included in the data set are gender, age, hypertension, heart disease, worktype, average glucose level, bmi, smoking status, and stroke. Previous literature suggest that heart disease, high blood pressure, diabetes, cholesterol levels, smoking status, age, and sex are risk factors. We would like to study if these risk factors, as well as the other covariates, are determine stroke in this data set. In this examination, we determine the most likely risk factors in this dataset and reveal a number of interesting interactions between covariates. We also build a model purely for prediction accuracy, and test the reliability of the data with a cross validation.



# Introduction

A stroke is a medical condition in which poor blood flow in the brain causes brain cell deaths. Strokes can be caused either by bleeding in the brain, which is classified as a hemorrhagic stroke, or by a lack of blood flow to the brain, which is classified as an ischemic stroke. Medical literature attributes many causes for a stroke: high blood pressure, cholesterol levels, and cardiovascular diseases can increase the risk of a stroke, most often by causing blood clots that may dislodge and then block blood vessels. Other conditions, such as diabetes, smoking, aneurysms, inflammation, and comorbidities may increase either the risk of having a stroke or the severity of it.

In this dataset is recorded several covariates:

Our main goal will be to correlate stroke with the other variables to asses them as risk factors.

1) gender: "Male", "Female" or "Other"

2) age: age of the patient

3) hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension

4) heart disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease 

5) ever-married: "No" or "Yes"

6) worktype: "children", "Govtjov", "Neverworked", "Private" or "Self-employed" 

7) Residencetype: "Rural" or "Urban"

8) avgglucoselevel: average glucose level in blood

9) bmi: body mass index

10) smoking_status: "formerly smoked", "never smoked", "smokes" or "Unknown"*

11) stroke: 1 if the patient had a stroke or 0 if not


The presence of many categorical and continuous covariates poses a challenge, and we will make a note to be wary of confounders and paradoxes, such as we will soon find in the relationship between Stroke, Age, and BMI. We will investigate such interactions with models and plots.



# Exploration

## First steps

The first step to understanding a (small enough) dataset is to view the covariates individually. With some quick summary statistics, we can get an idea of what we are looking at:

```{r first summary}
summary(data)
# data %>% group_by(smoking_status) %>% tally()
# data %>% group_by(ever_married) %>% tally()
# data %>% group_by(gender) %>% tally()
# data %>% group_by(work_type) %>% tally()
# data %>% group_by(Residence_type) %>% tally()
hist(age)

```
As expected, the value of stroke is either 0 or 1. Age, somewhat surprisingly, varies all the way from 0.08 to 82. It is clear from the dataset the low ages are not misinputs, so we may assume that our study includes data about very young patients. BMI varies from 14 to 48, reasonable values for a human dataset. We may also see that there are a large amount of unknown smoking statuses (about 1/3ish of the patients), both heart disease and hypertension have relatively low occurence (less than 10%), most patients were married, and there are more female patients than male. Literature suggests that stroke is more likely in young male patients, but the longer life expectancy of female subjects creates a survival bias that inflates the prevalence among older female patients. It remains to be seen if this is observered in our dataset. Furthermore, the ages are roughly evenly distributed, with no especially large tendency towards young or old. 

It was not mentioned how average blood glucose levels were measured, but it is most likely with an A1c screening. Thus, we might try to use average blood glucose levels as a stand in for diabetes. We may use average blood glucose as a continuous covariate to preserve accuracy, or we may attempt to stratify into normal (<117 mg/dL), prediabetic (117-137 mg/dl), and diabetic (>137 mg/dL) for ease of interpretation. 



## Some plots

Now that we've gotten our bearings a little, we can ask the plots for the simplest questions. Firstly, how does stroke risk vary with our continuous covariates?

```{r some plots and models}
plot(stroke~age)

fitage = glm(stroke ~ age, family = binomial, data = data)
smm = summary(fitage)
smm$coefficients
lines(sort(fitted.values(fitage))~sort(age), type = "l", col = "red")
```
In the above plot (code can be found in the EDAvisual.R file), we plot the occurrences of stroke/no stroke against age. Overlaid in a red line is a glm, fitting risk of stroke against age. The glm estimates an 0.075 increase in odds per year increase in age. Furthermore, the null over residual deviance suggests that the fit is relatively appropriate, and we do not worry yet about zero inflations or other potential issues quite yet. First, we investigate the other bivariate cases to satisfy our intuition.



Since we have observed that age increases risk, what about BMI?
```{r bmi}
plot(stroke~bmi)

fitage = glm(stroke ~ bmi, family = binomial, data = data)
summary(fitage)$coefficients
lines(sort(fitted.values(fitage))~sort(bmi), type = "l", col = "red")

```
In the above plot, we now see that BMI is associated with an increasing risk of stroke. Furthermore, we will a similar association in average blood glucose levels below:

```{r average glucose}
plot(stroke~avg_glucose_level)

fitage = glm(stroke ~ avg_glucose_level, family = binomial, data = data)
summary(fitage)$coefficients
lines(sort(fitted.values(fitage))~sort(avg_glucose_level), type = "l", col = "red")

```

Now we may move on to the categorical covariates: these may be investigated with a table.

```{r boxplots}
tab = data %>% group_by(smoking_status,stroke) %>% tally()
s = tab %>% filter(stroke == 1)
ns = tab %>% filter(stroke == 0)

s
ns
props = s$n/(s$n+ns$n)
barplot(s$n/(s$n+ns$n)~s$smoking_status)
barplot(s$n~s$smoking_status)
```

What a strange trend! The prevalence of stroke among never smoked and smokes is similar, while the prevalence in former smokers is much higher! It is biologically unlikely that smoking then stopping has a special ability to prevent strokes. It is more likely that there is some kind of multiple dependence or sample bias: maybe those who formerly smoked stopped because they experienced a health complication, or those who had the time to smoke then stop tended to be older. There is no clear way to interpret such bias without sampling more data, so we are stuck with only speculation.


Moving on, we may next take a look at hypertension and heart disease. Since both of these are strongly medically related, I will plot them with interaction. 

```{r hypertension and heart disease}
tab = data %>% group_by(hypertension,heart_disease,stroke) %>% tally()
sp = tab %>% filter(stroke == 1)
sn = tab %>% filter(stroke == 0)
prev = sp$n/(sp$n+sn$n)
barplot(prev~c("none",
               "heart disease",
               "hypertension",
               "both"))
tab

fit = glm(stroke ~ -1+I((!hypertension)*(!heart_disease))+I(hypertension*(!heart_disease))+I((!hypertension)*(heart_disease))+I(hypertension*heart_disease), family = binomial, data = data)
summary(fit)$coefficients
matrix(prev,2)
matrix(prev,2) %>% chisq.test()

fit = glm(heart_disease~hypertension, family = binomial, data = data)
summary(fit)

```

From the bar plot, we can see that those with both heart disease and hypertension have the most risk. Then, in descending order, heart disease only, hypertension only, and none. The model is kind enough to tell us that these differences are significant. We can also use a simple glm to determine that those with hypertension have a significantly higher risk of also having heart disease, indicating that these two covariates are indeed related.


Now that we have some intuition about what to expect, we can move on to all the covariates in one model.

```{r gender}
fit = glm(stroke ~ ., family = binomial, data = data)
summary(fit)$coefficients
#step(fit, direction = "both")
# y = as.matrix(stroke)
# x = cbind(
#   data$gender == "Female",
#   data$age,
#   data$hypertension,
#   data$heart_disease,
#   data$ever_married,
#   data$avg_glucose_level,
#   data$bmi,
#   data$smoking_status
# ) %>% as.matrix()
# fit = glmnet(x,y)
# plot(fit)
```


In our model, we have some surprising results: gender, heart disease, smoking status, and bmi are no longer significant! This may be due to some form of multicollinearity between it and the significant variables, but we would suspect these covariates to be significant regardless of multiple dependence. Gender, for example, is suggested to be a significant risk factor, but only depending on age. Smoking status was also supposed to be a risk factor, and intuitively should not be completely dependent on the others as we do not have a variable for heart disease.
We also tried multiple variable selection techniques, such as forwards/backwards/bidirectional stepwise selection and LASSO. These did not yield any further insight, and they will be relegated to the EDA.r file. So, lets investigate further.

Our next model will be a generalized additive model. This type of model allows for easy semiparametric multivariate modelling because of the additive treatment of the multiple dimensions univariately as well as capability for multivariate smoothing, such as with tensor product splines. We can then test for nonlinear relationships and for interactions. First, we establish a base model with only the significant covariates from the full model as well as BMI, which we suspect to be relevant:



```{r gam base}
fit = glm(stroke ~ age+hypertension+avg_glucose_level+bmi, family = binomial, data = data)
summary(fit)$coefficients
```

## A side-note about semi-parametric generalized additive models:

In case you're not familiar with the tensor product splines and the SS-ANOVA in spline models, special multivariate models called "tensor product splines" can be constructed from the Reproducing Kernel Hilbert Space point of view. The details are beyond the scope of this report, but the punchline is that the model space can be broken up into a collection of orthogonal subspaces. The fact that these subspaces are orthogonal allows for an ANOVA based of deviances explained, so that smooth terms in the model can be "significance tested." The unpenalized subspace, or the parametric part, is allowed to vary completely freely to minimize the objective function. In practice, these are very rigid and interpretable subspaces, such as the subspace of linear models. The non-parametric part, or smooth term, is a shape-fitting regression that can adjust to any shape, but is prevented from overfitting by a penalty functional. The classical non-parametric regression is the cubic smoothing spline. Popular nowadays are Gaussian Process Regressions and Regression Splines. The splines implemented by the MGCV package are not "true" RKHS regressions, but rather regression splines with automatically chosen knot points. Under nice enough data, these approximate the kernel regressions fitted by smoothing splines with much better computational performance. More advanced smoothing splines, such as arbitrary kernel regressions or semiparametric mixed effect models, would be better fit by a package like GSS or ASSIST.


## Back to the GAM

When we fit the GAM below, we include the following things: linear terms for age, bmi, hypertension, and average glucose level. Then we include smooth terms for age, bmi, and the interaction between age and bmi. 

```{r gam interactions}
fit = gam(stroke ~ age+bmi+hypertension+avg_glucose_level+ti(age)+ti(bmi)+ti(age,bmi), family = binomial, data = data)
summary(fit)$p.table
summary(fit)$s.table

#gam.check(fit)
```
To read the above summary, we note that BMI's linear term has become significant and the interaction term "ti(age,bmi)" is significant! This indicates that there is some kind of an interaction between age and bmi in how they predict the risk of stroke. Before we move on, because of the fickle nature of non-parametric models, it is prudent to check with a couple extra models just to be sure it is not a fluke. Below, we fit a bivariate cubic spline, a main-effect adjusted bivariate cubic spline, and a gaussian process smooth.



```{r check if fluke}
fit = gam(stroke ~ age+bmi+hypertension+avg_glucose_level+s(age,bmi), family = binomial, data = data)
summary(fit)$s.table

fit = gam(stroke ~ age+bmi+hypertension+avg_glucose_level+ti(age)+ti(bmi)+s(age,bmi), family = binomial, data = data)
summary(fit)$s.table

fit = gam(stroke ~ age+bmi+hypertension+avg_glucose_level+ti(age)+ti(bmi)+s(age,bmi, bs = "gp"), family = binomial, data = data)
summary(fit)$s.table
```
Because they all 


[Variance by Components](outputs/variancebycomponents.tiff)

